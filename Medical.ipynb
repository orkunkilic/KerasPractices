{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31034483],\n",
       "       [0.89655172],\n",
       "       [0.74712644],\n",
       "       ...,\n",
       "       [0.89655172],\n",
       "       [0.44827586],\n",
       "       [0.73563218]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 0s - loss: 0.6963 - accuracy: 0.4652\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6723 - accuracy: 0.5714\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.6466 - accuracy: 0.6486\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.6243 - accuracy: 0.7029\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.6010 - accuracy: 0.7252\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.5763 - accuracy: 0.7495\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.5504 - accuracy: 0.7771\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.5227 - accuracy: 0.8081\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.4925 - accuracy: 0.8281\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.4625 - accuracy: 0.8533\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.4352 - accuracy: 0.8700\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.4104 - accuracy: 0.8814\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3883 - accuracy: 0.8848\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3694 - accuracy: 0.8938\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.3531 - accuracy: 0.8990\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.3388 - accuracy: 0.9110\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.3270 - accuracy: 0.9024\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.3170 - accuracy: 0.9148\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.3086 - accuracy: 0.9224\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.3017 - accuracy: 0.9190\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2958 - accuracy: 0.9229\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2908 - accuracy: 0.9238\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2865 - accuracy: 0.9276\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2828 - accuracy: 0.9238\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2796 - accuracy: 0.9319\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2769 - accuracy: 0.9324\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2743 - accuracy: 0.9300\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2726 - accuracy: 0.9352\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2706 - accuracy: 0.9343\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2690 - accuracy: 0.9329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d136f25448>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "189/189 - 0s - loss: 0.6815 - accuracy: 0.5852 - val_loss: 0.6547 - val_accuracy: 0.6810\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.6506 - accuracy: 0.6471 - val_loss: 0.6160 - val_accuracy: 0.7286\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.6219 - accuracy: 0.6862 - val_loss: 0.5815 - val_accuracy: 0.7571\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.5938 - accuracy: 0.7275 - val_loss: 0.5486 - val_accuracy: 0.7810\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.5662 - accuracy: 0.7524 - val_loss: 0.5206 - val_accuracy: 0.8190\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.5395 - accuracy: 0.7857 - val_loss: 0.4912 - val_accuracy: 0.8238\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.5134 - accuracy: 0.8032 - val_loss: 0.4650 - val_accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.4880 - accuracy: 0.8307 - val_loss: 0.4409 - val_accuracy: 0.8905\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.4633 - accuracy: 0.8429 - val_loss: 0.4156 - val_accuracy: 0.8952\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.4398 - accuracy: 0.8608 - val_loss: 0.3940 - val_accuracy: 0.9048\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.4179 - accuracy: 0.8730 - val_loss: 0.3731 - val_accuracy: 0.9143\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.3977 - accuracy: 0.8820 - val_loss: 0.3549 - val_accuracy: 0.9143\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.3792 - accuracy: 0.8937 - val_loss: 0.3356 - val_accuracy: 0.9143\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.3633 - accuracy: 0.8937 - val_loss: 0.3240 - val_accuracy: 0.9286\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.3490 - accuracy: 0.9011 - val_loss: 0.3112 - val_accuracy: 0.9333\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.3368 - accuracy: 0.9095 - val_loss: 0.2982 - val_accuracy: 0.9333\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.3260 - accuracy: 0.9164 - val_loss: 0.2877 - val_accuracy: 0.9333\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.3169 - accuracy: 0.9164 - val_loss: 0.2829 - val_accuracy: 0.9381\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.3093 - accuracy: 0.9212 - val_loss: 0.2748 - val_accuracy: 0.9381\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.3025 - accuracy: 0.9291 - val_loss: 0.2659 - val_accuracy: 0.9381\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2972 - accuracy: 0.9254 - val_loss: 0.2612 - val_accuracy: 0.9381\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2924 - accuracy: 0.9307 - val_loss: 0.2574 - val_accuracy: 0.9381\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2884 - accuracy: 0.9323 - val_loss: 0.2536 - val_accuracy: 0.9381\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2851 - accuracy: 0.9323 - val_loss: 0.2504 - val_accuracy: 0.9381\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2822 - accuracy: 0.9344 - val_loss: 0.2484 - val_accuracy: 0.9381\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2798 - accuracy: 0.9376 - val_loss: 0.2448 - val_accuracy: 0.9381\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2779 - accuracy: 0.9365 - val_loss: 0.2433 - val_accuracy: 0.9381\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2757 - accuracy: 0.9386 - val_loss: 0.2418 - val_accuracy: 0.9381\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2740 - accuracy: 0.9407 - val_loss: 0.2397 - val_accuracy: 0.9381\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2727 - accuracy: 0.9392 - val_loss: 0.2392 - val_accuracy: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d138005048>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x=scaled_train_samples, y=train_labels, validation_split=.1, batch_size=10, epochs=30, shuffle=True, verbose=2)\n",
    "# Seperating validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = np.array(test_samples)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(x=scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9326789  0.06732117]\n",
      "[0.12721154 0.8727884 ]\n",
      "[0.05609027 0.94390976]\n",
      "[0.94699234 0.05300769]\n",
      "[0.06311792 0.9368821 ]\n",
      "[0.29109767 0.70890236]\n",
      "[0.02550525 0.97449476]\n",
      "[0.9409095  0.05909053]\n",
      "[0.21780948 0.78219056]\n",
      "[0.9448795  0.05512056]\n",
      "[0.9452756  0.05472443]\n",
      "[0.34725815 0.65274185]\n",
      "[0.9389929 0.0610071]\n",
      "[0.028399 0.971601]\n",
      "[0.07989804 0.92010194]\n",
      "[0.03161045 0.9683896 ]\n",
      "[0.04980354 0.95019644]\n",
      "[0.01484324 0.9851568 ]\n",
      "[0.9469923  0.05300769]\n",
      "[0.9433772  0.05662283]\n",
      "[0.94598854 0.05401148]\n",
      "[0.31851897 0.68148106]\n",
      "[0.9448795  0.05512056]\n",
      "[0.028399 0.971601]\n",
      "[0.9465932  0.05340679]\n",
      "[0.660072   0.33992797]\n",
      "[0.40801725 0.5919827 ]\n",
      "[0.08994882 0.91005117]\n",
      "[0.63044864 0.36955133]\n",
      "[0.07095992 0.92904013]\n",
      "[0.08994882 0.91005117]\n",
      "[0.17691016 0.82308984]\n",
      "[0.1011249 0.8988751]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.12721154 0.8727884 ]\n",
      "[0.93580776 0.06419221]\n",
      "[0.94215566 0.05784434]\n",
      "[0.9438708  0.05612919]\n",
      "[0.028399 0.971601]\n",
      "[0.08994882 0.91005117]\n",
      "[0.01844458 0.9815554 ]\n",
      "[0.02550525 0.97449476]\n",
      "[0.93963814 0.06036187]\n",
      "[0.87635356 0.12364642]\n",
      "[0.94567746 0.05432263]\n",
      "[0.9214851  0.07851492]\n",
      "[0.6884939  0.31150606]\n",
      "[0.9456332  0.05436684]\n",
      "[0.88971335 0.11028668]\n",
      "[0.88971335 0.11028668]\n",
      "[0.1011249 0.8988751]\n",
      "[0.9214851  0.07851492]\n",
      "[0.9433772  0.05662283]\n",
      "[0.86162704 0.1383729 ]\n",
      "[0.07989804 0.92010194]\n",
      "[0.01094026 0.9890597 ]\n",
      "[0.01484324 0.9851568 ]\n",
      "[0.03929188 0.9607081 ]\n",
      "[0.7411652  0.25883475]\n",
      "[0.94807184 0.05192818]\n",
      "[0.0441884 0.9558116]\n",
      "[0.7155636  0.28443637]\n",
      "[0.9409095  0.05909053]\n",
      "[0.660072   0.33992797]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.5998091 0.4001909]\n",
      "[0.9439034  0.05609666]\n",
      "[0.9471982  0.05280178]\n",
      "[0.11351647 0.8864835 ]\n",
      "[0.5363665  0.46363348]\n",
      "[0.03161045 0.9683896 ]\n",
      "[0.14229365 0.8577063 ]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.9388009  0.06119914]\n",
      "[0.34725815 0.65274185]\n",
      "[0.93580776 0.06419221]\n",
      "[0.9438708  0.05612919]\n",
      "[0.17691016 0.82308984]\n",
      "[0.01654786 0.98345214]\n",
      "[0.82777286 0.17222711]\n",
      "[0.5363665  0.46363348]\n",
      "[0.86162704 0.1383729 ]\n",
      "[0.03517189 0.9648281 ]\n",
      "[0.9439034  0.05609666]\n",
      "[0.34725815 0.65274185]\n",
      "[0.31851897 0.68148106]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.03161045 0.9683896 ]\n",
      "[0.21780948 0.78219056]\n",
      "[0.31851897 0.68148106]\n",
      "[0.9282049  0.07179508]\n",
      "[0.06311792 0.9368821 ]\n",
      "[0.08994882 0.91005117]\n",
      "[0.7411652  0.25883478]\n",
      "[0.40801725 0.5919827 ]\n",
      "[0.05609027 0.94390976]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.21780948 0.78219056]\n",
      "[0.9469923  0.05300769]\n",
      "[0.12721154 0.8727884 ]\n",
      "[0.31851897 0.68148106]\n",
      "[0.845456   0.15454398]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.34725815 0.65274185]\n",
      "[0.02550525 0.97449476]\n",
      "[0.9414904  0.05850956]\n",
      "[0.03929188 0.9607081 ]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.9448795  0.05512056]\n",
      "[0.9282049  0.07179508]\n",
      "[0.940277   0.05972304]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.9433772  0.05662283]\n",
      "[0.94153565 0.05846431]\n",
      "[0.7652185  0.23478149]\n",
      "[0.6884939  0.31150606]\n",
      "[0.94807184 0.05192818]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.26511854 0.73488146]\n",
      "[0.9214851  0.07851492]\n",
      "[0.5683682  0.43163183]\n",
      "[0.94699234 0.05300769]\n",
      "[0.94699234 0.05300769]\n",
      "[0.5683682  0.43163183]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.03517189 0.9648281 ]\n",
      "[0.43962234 0.56037766]\n",
      "[0.9282049  0.07179508]\n",
      "[0.03161045 0.9683896 ]\n",
      "[0.845456   0.15454398]\n",
      "[0.21780948 0.78219056]\n",
      "[0.9476823  0.05231765]\n",
      "[0.01844458 0.9815554 ]\n",
      "[0.34725815 0.65274185]\n",
      "[0.94276947 0.05723052]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.8085246  0.19147536]\n",
      "[0.63044864 0.36955133]\n",
      "[0.01654786 0.98345214]\n",
      "[0.06311792 0.9368821 ]\n",
      "[0.9326789  0.06732117]\n",
      "[0.028399 0.971601]\n",
      "[0.9475347 0.0524653]\n",
      "[0.31851897 0.68148106]\n",
      "[0.08994882 0.91005117]\n",
      "[0.0441884 0.9558116]\n",
      "[0.07095992 0.92904013]\n",
      "[0.29109767 0.70890236]\n",
      "[0.94153565 0.05846431]\n",
      "[0.9465932  0.05340679]\n",
      "[0.5040626  0.49593738]\n",
      "[0.40801725 0.5919827 ]\n",
      "[0.12721154 0.8727884 ]\n",
      "[0.15883848 0.84116155]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.94276947 0.05723052]\n",
      "[0.5363665  0.46363348]\n",
      "[0.03929188 0.9607081 ]\n",
      "[0.9214851  0.07851492]\n",
      "[0.845456   0.15454398]\n",
      "[0.93580776 0.06419221]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.9465932  0.05340679]\n",
      "[0.31851897 0.68148106]\n",
      "[0.6884939  0.31150606]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.93963814 0.06036187]\n",
      "[0.34725815 0.65274185]\n",
      "[0.94598854 0.05401148]\n",
      "[0.15883848 0.84116155]\n",
      "[0.9465932  0.05340679]\n",
      "[0.03517189 0.9648281 ]\n",
      "[0.9452756  0.05472443]\n",
      "[0.94634175 0.0536583 ]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.9389929 0.0610071]\n",
      "[0.43962234 0.56037766]\n",
      "[0.03517189 0.9648281 ]\n",
      "[0.90179133 0.09820864]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.9476823  0.05231765]\n",
      "[0.21780948 0.78219056]\n",
      "[0.94634175 0.0536583 ]\n",
      "[0.93580776 0.06419221]\n",
      "[0.94276947 0.05723052]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.86162704 0.1383729 ]\n",
      "[0.9466927  0.05330728]\n",
      "[0.0441884 0.9558116]\n",
      "[0.82777286 0.17222711]\n",
      "[0.9389929 0.0610071]\n",
      "[0.660072   0.33992797]\n",
      "[0.88971335 0.11028668]\n",
      "[0.63044864 0.36955133]\n",
      "[0.94276947 0.05723052]\n",
      "[0.9326789  0.06732117]\n",
      "[0.1011249 0.8988751]\n",
      "[0.940277   0.05972304]\n",
      "[0.94276947 0.05723052]\n",
      "[0.01844458 0.9815554 ]\n",
      "[0.1011249 0.8988751]\n",
      "[0.7652185  0.23478149]\n",
      "[0.02550525 0.97449476]\n",
      "[0.31851897 0.68148106]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.15883848 0.84116155]\n",
      "[0.9433772  0.05662283]\n",
      "[0.912402  0.0875981]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.9476823  0.05231765]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.07989804 0.92010194]\n",
      "[0.17691016 0.82308984]\n",
      "[0.07989804 0.92010194]\n",
      "[0.12721154 0.8727884 ]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.26511854 0.73488146]\n",
      "[0.9472642  0.05273584]\n",
      "[0.94567746 0.05432263]\n",
      "[0.01094026 0.9890597 ]\n",
      "[0.05609027 0.94390976]\n",
      "[0.5040626  0.49593738]\n",
      "[0.9214851  0.07851492]\n",
      "[0.028399 0.971601]\n",
      "[0.43962234 0.56037766]\n",
      "[0.9475347 0.0524653]\n",
      "[0.028399 0.971601]\n",
      "[0.21780948 0.78219056]\n",
      "[0.93580776 0.06419221]\n",
      "[0.94634175 0.0536583 ]\n",
      "[0.7411652  0.25883478]\n",
      "[0.787677   0.21232302]\n",
      "[0.912402  0.0875981]\n",
      "[0.01844458 0.9815554 ]\n",
      "[0.9389929 0.0610071]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.8085246  0.19147536]\n",
      "[0.93963814 0.06036187]\n",
      "[0.43962234 0.56037766]\n",
      "[0.31851897 0.68148106]\n",
      "[0.9452756  0.05472443]\n",
      "[0.787677   0.21232302]\n",
      "[0.5363665  0.46363348]\n",
      "[0.02550525 0.97449476]\n",
      "[0.9409095  0.05909053]\n",
      "[0.93580776 0.06419221]\n",
      "[0.7652185  0.23478149]\n",
      "[0.9389929 0.0610071]\n",
      "[0.9452756  0.05472443]\n",
      "[0.940277   0.05972304]\n",
      "[0.912402  0.0875981]\n",
      "[0.17691016 0.82308984]\n",
      "[0.9475347 0.0524653]\n",
      "[0.03517189 0.9648281 ]\n",
      "[0.94276947 0.05723052]\n",
      "[0.028399 0.971601]\n",
      "[0.028399 0.971601]\n",
      "[0.9476823  0.05231765]\n",
      "[0.87635356 0.12364642]\n",
      "[0.9409095  0.05909053]\n",
      "[0.12721154 0.8727884 ]\n",
      "[0.94598854 0.05401148]\n",
      "[0.11351647 0.8864835 ]\n",
      "[0.07095992 0.92904013]\n",
      "[0.9282049  0.07179508]\n",
      "[0.5683682  0.43163183]\n",
      "[0.912402  0.0875981]\n",
      "[0.660072   0.33992797]\n",
      "[0.94699234 0.05300769]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.14229365 0.8577063 ]\n",
      "[0.11351647 0.8864835 ]\n",
      "[0.787677   0.21232302]\n",
      "[0.9452756  0.05472443]\n",
      "[0.05609027 0.94390976]\n",
      "[0.87635356 0.12364642]\n",
      "[0.912402  0.0875981]\n",
      "[0.11351647 0.8864835 ]\n",
      "[0.5998091 0.4001909]\n",
      "[0.5998091 0.4001909]\n",
      "[0.07989804 0.92010194]\n",
      "[0.5040626  0.49593738]\n",
      "[0.9439034  0.05609666]\n",
      "[0.94276947 0.05723052]\n",
      "[0.01094026 0.9890597 ]\n",
      "[0.02289939 0.9771006 ]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.94567746 0.05432263]\n",
      "[0.9414904  0.05850956]\n",
      "[0.7652185  0.23478149]\n",
      "[0.88971335 0.11028668]\n",
      "[0.9388009  0.06119914]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.9439034  0.05609666]\n",
      "[0.9466927  0.05330728]\n",
      "[0.8085246  0.19147536]\n",
      "[0.31851897 0.68148106]\n",
      "[0.17691016 0.82308984]\n",
      "[0.94153565 0.05846431]\n",
      "[0.028399 0.971601]\n",
      "[0.05609027 0.94390976]\n",
      "[0.0441884 0.9558116]\n",
      "[0.9444248  0.05557523]\n",
      "[0.5040626  0.49593738]\n",
      "[0.08994882 0.91005117]\n",
      "[0.43962234 0.56037766]\n",
      "[0.9465932  0.05340679]\n",
      "[0.11351647 0.8864835 ]\n",
      "[0.63044864 0.36955133]\n",
      "[0.05609027 0.94390976]\n",
      "[0.03929188 0.9607081 ]\n",
      "[0.29109767 0.70890236]\n",
      "[0.9444248  0.05557523]\n",
      "[0.94699234 0.05300769]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.40801725 0.5919827 ]\n",
      "[0.9439034  0.05609666]\n",
      "[0.94699234 0.05300769]\n",
      "[0.05609027 0.94390976]\n",
      "[0.82777286 0.17222711]\n",
      "[0.07989804 0.92010194]\n",
      "[0.24067095 0.7593291 ]\n",
      "[0.93580776 0.06419221]\n",
      "[0.845456   0.15454398]\n",
      "[0.0441884 0.9558116]\n",
      "[0.06311792 0.9368821 ]\n",
      "[0.6884939  0.31150606]\n",
      "[0.43962234 0.56037766]\n",
      "[0.94807184 0.05192818]\n",
      "[0.02055415 0.9794459 ]\n",
      "[0.9438708  0.05612919]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.9466927  0.05330728]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.07989804 0.92010194]\n",
      "[0.08994882 0.91005117]\n",
      "[0.34725815 0.65274185]\n",
      "[0.93580776 0.06419221]\n",
      "[0.26511854 0.73488146]\n",
      "[0.01094026 0.9890597 ]\n",
      "[0.94567746 0.05432263]\n",
      "[0.9448795  0.05512056]\n",
      "[0.17691016 0.82308984]\n",
      "[0.845456   0.15454398]\n",
      "[0.947804   0.05219609]\n",
      "[0.87635356 0.12364642]\n",
      "[0.7411652  0.25883478]\n",
      "[0.660072   0.33992797]\n",
      "[0.947804   0.05219609]\n",
      "[0.8085246  0.19147536]\n",
      "[0.6884939  0.31150606]\n",
      "[0.94276947 0.05723052]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.02550525 0.97449476]\n",
      "[0.29109767 0.70890236]\n",
      "[0.787677   0.21232302]\n",
      "[0.9439034  0.05609666]\n",
      "[0.0441884 0.9558116]\n",
      "[0.4717247 0.5282754]\n",
      "[0.01844458 0.9815554 ]\n",
      "[0.29109767 0.70890236]\n",
      "[0.94276947 0.05723052]\n",
      "[0.94276947 0.05723052]\n",
      "[0.94807184 0.05192818]\n",
      "[0.9389929 0.0610071]\n",
      "[0.1011249 0.8988751]\n",
      "[0.9465932  0.05340679]\n",
      "[0.01654786 0.98345214]\n",
      "[0.94634175 0.0536583 ]\n",
      "[0.9472642  0.05273584]\n",
      "[0.40801725 0.5919827 ]\n",
      "[0.028399 0.971601]\n",
      "[0.07989804 0.92010194]\n",
      "[0.9471982  0.05280178]\n",
      "[0.9409095  0.05909053]\n",
      "[0.07095992 0.92904013]\n",
      "[0.02055415 0.9794459 ]\n",
      "[0.94807184 0.05192818]\n",
      "[0.9388009  0.06119914]\n",
      "[0.29109767 0.70890236]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.94276947 0.05723052]\n",
      "[0.94215566 0.05784434]\n",
      "[0.43962234 0.56037766]\n",
      "[0.21780948 0.78219056]\n",
      "[0.7652185  0.23478149]\n",
      "[0.01654786 0.98345214]\n",
      "[0.88971335 0.11028668]\n",
      "[0.37715533 0.6228447 ]\n",
      "[0.04980354 0.95019644]\n",
      "[0.028399 0.971601]\n",
      "[0.6884939  0.31150606]\n",
      "[0.01334599 0.986654  ]\n",
      "[0.02055415 0.9794459 ]\n",
      "[0.940277   0.05972304]\n",
      "[0.9456332  0.05436684]\n",
      "[0.02550525 0.97449476]\n",
      "[0.9282049  0.07179508]\n",
      "[0.02289939 0.9771006 ]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.29109767 0.70890236]\n",
      "[0.63044864 0.36955133]\n",
      "[0.9466927  0.05330728]\n",
      "[0.07989804 0.92010194]\n",
      "[0.02289939 0.9771006 ]\n",
      "[0.87635356 0.12364642]\n",
      "[0.14229365 0.8577063 ]\n",
      "[0.01208414 0.9879159 ]\n",
      "[0.02550525 0.97449476]\n",
      "[0.0441884 0.9558116]\n",
      "[0.21780948 0.78219056]\n",
      "[0.34725815 0.65274185]\n",
      "[0.19655757 0.8034424 ]\n",
      "[0.9466927  0.05330728]\n",
      "[0.0441884 0.9558116]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm =  confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], \n",
    "                 horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199  11]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEmCAYAAADBbUO1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd7hU1fn28e8NKKKggCJi771g74qaWGKPLfYWWzRqbEFjN/aSxF8s0deOvaOxobFHLCiKqFiCJipKsxcUvN8/1jo4Hg9z5rRpPB+vfZ2ZNWvvvWbkPGfNqrJNCCGE8uhU6QKEEML0JIJuCCGUUQTdEEIoowi6IYRQRhF0QwihjCLohhBCGUXQDTVHUjdJ90j6TNKtbbjOrpIeas+yVYKk+yXtWelyhNJE0A0dRtIukl6Q9KWkMTk4rNMOl94e6AvMbnuH1l7E9vW2N26H8vyEpAGSLOmORukr5PTHSrzOyZIGNZfP9ma2r2llcUOZRdANHULSEcBfgTNIAXJ+4GJg63a4/ALAm7Ynt8O1Oso4YC1Jsxek7Qm82V43UBK/w7XGdhxxtOsBzAZ8CexQJE9XUlD+MB9/Bbrm1wYA7wNHAmOBMcDe+bVTgO+A7/M99gVOBgYVXHtBwECX/Hwv4D/AF8BoYNeC9KcKzlsLeB74LP9cq+C1x4DTgKfzdR4C5pjGe2so/6XAwTmtc047EXisIO/fgP8BnwPDgHVz+qaN3ufLBeU4PZfjG2DRnPbb/PolwG0F1z8beARQpf9dxJGO+CsZOsKawEzAnUXy/AlYA+gPrACsBhxf8PpcpOA9DymwXiSpl+2TSLXnm213t31FsYJImgW4ENjMdg9SYB3eRL7ewD9z3tmBC4B/Nqqp7gLsDcwJzAgcVezewLXAHvnxJsBI0h+YQs+TPoPewA3ArZJmsv1Ao/e5QsE5uwP7Az2A9xpd70hgeUl7SVqX9Nnt6RyBQ+VF0A0dYXZgvIt//d8VONX2WNvjSDXY3Qte/z6//r3t+0i1vSVaWZ4fgGUldbM9xvbIJvJsDrxl+zrbk23fCLwBbFmQ5yrbb9r+BriFFCynyfa/gd6SliAF32ubyDPI9oR8z/NJ3wCae59X2x6Zz/m+0fW+BnYj/dEYBPze9vvNXC+UUQTd0BEmAHNI6lIkz9z8tJb2Xk6beo1GQftroHtLC2L7K2An4EBgjKR/SlqyhPI0lGmegucftaI81wGHABvQRM1f0pGSXs8jMT4l1e7naOaa/yv2ou3nSM0pIv1xCFUkgm7oCM8A3wLbFMnzIalDrMH8/Pyrd6m+AmYueD5X4Yu2H7T9S6AfqfZ6eQnlaSjTB60sU4PrgN8B9+Va6FT56/8fgR2BXrZ7ktqT1VD0aVyzaFOBpINJNeYPgWNaX/TQESLohnZn+zNSh9FFkraRNLOkGSRtJumcnO1G4HhJfSTNkfM3OzxqGoYD60maX9JswLENL0jqK2mr3LY7idRMMaWJa9wHLJ6HuXWRtBOwNHBvK8sEgO3RwPqkNuzGegCTSSMdukg6EZi14PWPgQVbMkJB0uLAn0lNDLsDx0gq2gwSyiuCbugQti8AjiB1jo0jfSU+BLgrZ/kz8ALwCjACeDGnteZeQ4Cb87WG8dNA2YnUufQhMJEUAH/XxDUmAFvkvBNINcQtbI9vTZkaXfsp203V4h8E7icNI3uP9O2gsOmgYeLHBEkvNnef3JwzCDjb9su23wKOA66T1LUt7yG0H0WnZgghlE/UdEMIoYwi6IYQAiBpPkmP5tEkIyUdltN7Sxoi6a38s1dOl6QLJb0t6RVJK5Vynwi6IYSQTAaOtL0UaeLOwZKWBgYCj9hejDS7b2DOvxmwWD72J80GbFYE3RBCAPLEmRfz4y+A10njtLcGGhYUuoYfh0JuDVzrZCjQU1K/5u5TbPB6qAHq0s2asUeli1G3+i81f6WLUNf++967jB8/Xs3nbF7nWRewJ39TNI+/GTeSNEqkwWW2L2ucT9KCwIrAs0Bf22MgBWZJc+Zs8/DT0Sbv57QxxcoQQbfGacYedF1yp0oXo249PfTCShehrq29xqrtdi1P/oauS+xYNM+3wy/61vYqxfJI6g7cDhxu+3Npmn8Tmnqh2eFgEXRDCPVBgk6d23gJzUAKuNfbblgP+WNJ/XIttx9p5TtINdv5Ck6flxJmVUabbgihfqhT8aPYqalKewXwep7c02AwaS1k8s+7C9L3yKMY1gA+a2iGKCZquiGEOtHmmu7apKnTIyQ1LP95HHAWcIukfYH/Ag27ldwH/Ap4m7QA0t6l3CSCbgihfky7/bVZtp+i6XZagI2ayG/g4JbeJ4JuCKE+tEObbjlE0A0h1I8a2DIugm4IoU5ETTeEEMpHtKlNt1wi6IYQ6kc0L4QQQrkIOkfzQgghlIeImm4IIZRPdKSFEEJ5RUdaCCGUSUyOCCGEMos23RBCKJeo6YYQQnlFm24IIZRJDBkLIYRyapedI64EtgDG2l42p90MLJGz9AQ+td0/76P2OjAqvzbU9oHN3SOCbgihfrS9pns18Hfg2oYE21M3IZR0PvBZQf53bPdvyQ0i6IYQ6kM7DBmz/USuwTZxeQnYEdiwLfeo/gaQEEIolVT8aJt1gY9tv1WQtpCklyQ9LmndUi4SNd0QQl0Q0KlTs/XIOSS9UPD8MtuXlXiLnYEbC56PAea3PUHSysBdkpax/Xmxi0TQDSHUBzHtHc5+NN72Ki2+tNQF+DWwckOa7UnApPx4mKR3gMWBF5q8SBZBN4RQJ1RKTbe1fgG8Yfv9qXeT+gATbU+RtDCwGPCf5i4UbbohhLohqehRwvk3As8AS0h6P2+7DvAbftq0ALAe8Iqkl4HbgANtT2zuHlHTDSHUB4E6ta2zzPbO00jfq4m024HbW3qPCLohhLogSqvNVloE3RBC3YigG0IIZdSBHWntJoJuCKE+lDZkrOIi6IYQ6oI6dshYu4mgG0KoG9GmG0II5dIOQ8bKIYJuCKFu1EJNt/obQEJNufSkXXjv4TN44ZZjp6Ytt9g8PHb1ETx/87Hc9tf96THLTADM0KUz/zh5V56/+VievWkg6668aKWKXZMO2G8fFpinL6v0X25q2h233crKKyzLLF07M2xY0SUA6k5Dm26xoxpURylC3bjunmfZ+pCLf5J2yYk7c/yFg1l1pzMZ/Ogr/GGPjQDY59drAbDqTmeyxUF/56wjtq2Jmkq12H2Pvbjr3vt/krb0Msty4y23s86661WoVBWmZo4qEEE3tKunX3yHiZ99/ZO0xRaYk6defBuAfw19g202WgGAJReei0efSzudjPvkSz774htWXnr+8ha4hq2z7nr07tX7J2lLLrUUiy+xxDTOqHNq+9oL5RBBN3S4194Zwxbrp6/Av/7FiszbtxcAI978gC3XX57OnTuxwNyzs+JS8zFv356VLGqocdG8EAJwwCk3cMCO6/L09UfTfZaZ+O77KQBcc/dQPhj7KU8POppzj/o1Q18ezeQpP1S4tKGm1UDzQl2NXpC0FbC07bOaeO1L293b8V47AKcCH9neIC8Jtwxwle2/tOA6PYFdbF/cbOYa9ea7H7PlwentLTp/HzZbZxkApkz5gWPOv2Nqvkev+gNv/3dcRcoYap8UkyPKzvZgYHCZbrcv8Dvbj0qaC1jL9gKtuE5P4HdA3QbdPr26M+6TL5HEwN9uyuW3PwVAt5lmQIivv/2ODVdfgslTfuCN0R9VuLShllVLu20xFQm6ebfN+4GngLWAD4CtSXvLXwrMDLwD7GP7k2lc41DgQGAy8Jrt30jaC1jF9iGSFgJuIL3HBxqdezRpV8+uwJ22TypS1t2AQ4EZgWdJAfJPwDqkTekGA5sAc0oaDvwe+BC4COgDfA3sZ/sNSX3z+1s4X/6gfO1F8rlDgAuAm4FZc9kPsv1kkY+zqlxzxl6su/KizNGzO2/ffyqnXXof3WfuygE7pt70u//1MtfePRSAPr16cM9Fv+MHmw/Hfsa+J1xb7NKhkT1324UnnniMCePHs+hC83H8iSfTq1dvjvzDoYwfN47ttt6C5Vfoz+B/PtD8xepEWydHSLoS2AIYa3vZnHYysB/Q8DXsONv35deOJVXApgCH2n6w2XvYblMhWyMH3bdJAXK4pFtINdRjgN/bflzSqcCstg+fxjU+BBayPUlST9ufNgq6g4HbbF8r6WDgbNvdJW0MbA8cQGrlGQycY/uJJu6xFHAO8Gvb30u6GBiar/kYcJTtF/L7ubfgf9IjpFXk35K0OnCm7Q0l3Qw8Y/uvkjoD3YFejc49EpjJ9uk5z8y2v2hUrv2B/QGYofvKMy27V4s+/1C6ic9eWOki1LW111iVF4e90C7V0659F/M8u/6taJ7Rf9l8WLE90iStB3wJXNso6H5p+7xGeZcm7SaxGjA38DCwuO0pxcpQyeaF0baH58fDgEWAnrYfz2nXALcWOf8V4HpJdwF3NfH62sB2+fF1wNn58cb5eCk/707a2+hnQRfYiLQR3fP5a0s3YGyxNyWpO6n2fmvBV52u+eeGwB4A+X/MZ5J6NbrE88CVkmYA7ir4jKbKu5deBtBp5jnL/1czhCokQae27xzxRK5ElWJr4Ka8QeVoSW+TAvAzxU6qZNCdVPB4CqltsyU2J+1RtBVwgqRlmsjTVEASqeb5jxLuIeAa28c2m/NHnYBPbfdvwTlT5f/p65He33WSzrUd37tDaFZJY3FbuwX7IZL2IO30e2Ru9pwHGFqQ5/2cVlQ1dfV9Bnwiad38fHfg8aYySuoEzGf7UVKTRE9SjbXQ06TN5AB2LUh/ENgn10iRNI+kOadRpkeA7Rtel9RbUtHOsrzn/eg8ugElKxRc76Cc3lnSrMAXQI+C97YAqT3pcuAKYKVi9wsh/KhTJxU9yFuwFxylBNxLSN/E+wNjgPNzelMRvtlvntUUdAH2BM6V9ArpDZ46jXydgUGSRpCaCf5i+9NGeQ4DDpb0PDBbQ6Lth0gdbM/k82+jIOgVsv0acDzwUC7TEKBfCe9jV2DfvEvoSNLXkIYybZDvOwxYxvYE4GlJr0o6FxgADJf0Eql5pHgjVQghUWpiKHa0hu2PbU+x/QNwOakJAVLNdr6CrPOSOtGLF7MSHWmh/XSaeU53XXKnShejbkVHWsdqz460bv0W90J7/71ontfP3KRoRxpM7egv7NzuZ3tMfvwHYPU8WmoZUgWuoSPtEWCxau5ICyGEdtXWjrQ8yWkAqe33feAkYICk/qSmg3dJI5+wPTKPvHqNNHT14OYCLtRA0JV0EWkkQqG/2b6qHe8xO+mvVGMb5a//IYRq14YmhAa2d24i+Yoi+U8HTm/JPao+6No+uAz3mEBqQw4h1KjYIy2EEMqsBmYBR9ANIdSJdpgcUQ4RdEMIdUHEgjchhFBWUdMNIYQyqoGKbgTdEEKdUDQvhBBC2aQhYxF0QwihbGqgohtBN4RQJ2LIWAghlE8MGQshhDKr6ZqupDspsiCv7V93SIlCCKGVar2mW3xhyhBCqCJSjY9esD11qUNJMwLz2367LKUKIYRWaGtFdxpbsJ8LbAl8B7wD7J13H18QeB0YlU8favvA5u7R7DpokjYHRpC2qkFS/9z0EEIIVaVzJxU9SnA1sGmjtCHAsraXB94ECjeqfcd2/3w0G3ChtD3STgVWBz4FyFuCL1rKxUMIoVyUZ6QVO5pj+wlgYqO0h2xPzk+HkvZCa7VSgu73TWz6GBurhRCqTicVP8hbsBcc+7fwFvsA9xc8X0jSS5IeL9jJvKhShoy9LmlHoJOkhUg72g5t5pwQQii7EjrSxje3MeW0SPoTaS+063PSGFJf1wRJKwN3SVrG9udFy1jCvQ4BVgZ+AO4EJgGHt6bQIYTQUURaf6HYf62+trQnqYNtV+ct1G1PathD0fYwUifb4s1dq9maru2vgD9KOiU99TetLnkIIXQUldxZ1sLLalPgj8D6tr8uSO8DTLQ9RdLCwGLAf5q7XimjF1aS9BKp1+4tScMkrdTqdxBCCB1EKn40f75uBJ4BlpD0vqR9SXMWegBDJA2XdGnOvh7wiqSXgduAA21PbPLCBUpp070KONz2o7lQA3LaCiWcG0IIZSFoc023JVuw274duL2l9ygl6H7VEHDzjR6T9GVLbxRCCB2tpqcBS1o+P3xW0kXAjaShYjsBj07rvBBCqASp7TXdcihW072o0fPlCx7HON0QQtWp/pBbfO2Fkgb6hhBCtajp5oVCkjYBlgFmakizfUZHFSqEEFpKHTRkrL01G3QlXQz0JA2PuArYjpiRFkKoQjVQ0S1pRto6tncBJtg+gbT4TZsWfAghhPbWMGSsjauMdbhSmhcaZqB9K2kuYAKwYIeVKIQQWqle2nTvl9QTOA8YDkwBrunQUoUQQgtJ0Lkegq7tk/PDWyXdC3QDFurIQoUQQmvUQMxt2W7AebGbbyQNB+bvmCKFEELr1PQeac2o/ncWQpiuCNGpBqq6rQ26MSOtSqy41Pw8/ez/VboYdavXqodUugh1bdKo/7bfxVTjNd28+WRTwVXA7B1WohBCaKVSxsBWWrGa7t9b+VoIIZSdaPuQsWlswd4buJk0VPZdYEfbnyjd7G/Ar4Cvgb1sv9jcPYqtvfBIm0ofQghl1qXtVd2rSZXKawvSBgKP2D5L0sD8/I/AZqTdIhYjTRq7JP8sqhZq4yGE0KyO2oId2Jof5yZcA2xTkH6tk6FAT0n9mrtHazvSQgih6nRuvho5h6QXCp5fZvuyZs7pa3sMgO0xkubM6fMA/yvI935OG1PsYiUHXUldbU8qNX8IIZSToJQhY63egn0at2ys2ZFdpWxMuZqkEcBb+fkKkmKMUgih6nRW8aOVPm5oNsg/x+b094H5CvLNC3zY3MVKadO9kNSb17C/+8vABi0ocAghdDgpTY4odrTSYGDP/HhP4O6C9D2UrAF81tAMUUwpzQudbL/XqBF6SgsKHEIIZVFCm25ReQv2AaS23/eBk4CzgFvyduz/BXbI2e8jDRd7mzRkbO9S7lFK0P2fpNUAS+oM/B54swXvI4QQOlyJbbpFTWMLdoCNmshr4OCW3qOUoHsQqYlhfuBj4OGcFkIIVaUGll4oaWnHscBvylCWEEJovXpZT1fS5TQxDML2/h1SohBCaIXUvFDpUjSvlOaFhwsezwRsy08HBIcQQlWoln3QiimleeHmwueSrgOGdFiJQgihFeqpptvYQsAC7V2QEEJoE9VJTVfSJ/zYptuJtBjEwI4sVAghtFRd1HTzepErAB/kpB/y2LQQQqgyqonRC0Xnb+QAe6ftKfmIgBtCqEppEfPiRzUoZdLcc5JW6vCShBBCWwi6dFLRoxoU2yOti+3JwDrAfpLeAb4i/UGx7QjEIYSq0VDTrXbF2nSfA1bix1XSQwihqtX6FuwCsP1OmcoSQgitJtq0Zm7ZFAu6fSQdMa0XbV/QAeUJIYTWUdt3Ay6HYkG3M9CdprekCCGEqpJqum3egn0J0nbrDRYGTgR6AvsB43L6cbbva809igXdMbZPbc1FQwihEtpaQ7Q9CugPkNcP/wC4k7RA+V9sn9fGWzTfphtCCLVBdGrfYWEbAe80sXNOmxQbp/uzldJDCKFaiRTQih0t9BvgxoLnh0h6RdKVknq1tpzTLIftia29aAghVEIJG1POIemFgqPJdcElzQhsBdyaky4BFiE1PYwBzm9tGVuzylgIIVSf0kYvjLe9SglX2wx40fbHAA0/YerGDve2tpht3DszhBCqQzs3L+xMQdOCpH4Fr20LvNrackZNN4RQN9pjRpqkmYFfAgcUJJ8jqT9pmdt3G73WIhF0Qwh1oz0GGdj+Gpi9Udrubb9yEkE3hFAX2mNyRDlE0A0h1AmhGpheEEE3hFAXoqYbQgjlVEW7QxQTQ8ZChzngt/sw/9xzsnL/ZaemTZw4kc03/SXLLrUYm2/6Sz755JMKlrD2zNu3Jw9cdigv3X48w277EwfvPACAXrPOzL2XHMKIu0/k3ksOoWePblPPOf+Y7Xn17pN47uZj6b/kvBUqeXmUMDmi4iLohg6z+557cfe9D/wk7bxzzmLAhhvx6utvMWDDjTjvnLMqVLraNHnKDwy84A5W3O7PrL/HeRyw03osufBcHLX3L3nsuVEst/WpPPbcKI7ae2MANllnaRaZvw/Lbn0Kh/z5Ri487jcVfgcdp2E34GJHNYigGzrMOuuuR+/evX+Sdu89d7Pb7nsCsNvue3LP4LsqUbSa9dH4zxn+xvsAfPn1JN4Y/RFz9+nJFgOWZ9A9zwIw6J5n2XKD5QHYYv3lueHe5wB4bsS7zNajG3PNMWtlCl8GUdMNoZGxH39Mv35pck+/fv0YN3ZshUtUu+bv15v+S8zL86++y5yz9+Cj8Z8DKTD36d0DgLnn7Mn7H/3YhPPBx58y95w9K1LeclAz/1WD6EgLoQbN0m1Gbjzvtxx93u188dW308zXVOXOdgeWrHIamheqXYfVdCUtKKnV85MlfdmKc+6T9LM/45JOlnRUa8vSxPW6SnpY0nBJO0laV9LI/Lxb81f4ybW2kbR0e5Wt2s3Zty9jxowBYMyYMfSZc84Kl6j2dOnSiRvP24+b73+Bu//1MgBjJ3wxtdlgrjlmZdzEL4BUs513rh9XIZynb0/GjPus/IUuh2aaFqJ5oQPY/pXtT8twqxWBGWz3t30zsCtwXn7+TQuvtQ0w3QTdzbfYikHXXQPAoOuuYYstt65wiWrPpSftyqjRH3HhoH9NTfvn4yPYbcvVAdhty9W597FXpqbvssVqAKy23IJ8/uU3U5sh6pGaOapBRwfdzpIuz7XAhyR1k7SfpOclvSzp9ry4BJIWkvRMfu20YheV1E/SE7lm+aqkdXP6u5LmyI//JGmUpIeBJQrOXUTSA5KGSXpS0pJF7tMnl/H5fKwtaU5gENA/3/8AYEfgREnX5/OOzvlfkXRKwfX2yGkvS7pO0lqkNTvPzddaRNKhkl7L+W6aRrn2b1gPdNz4cU1lqQp77LYzA9ZdkzdHjWKRBefl6iuv4KhjBvKvh4ew7FKL8a+Hh3DUMQMrXcyaslb/hdl1i9VZf9XFGXrTQIbeNJBN1lma864awoarL8mIu09kw9WX5LyrhgDwwFMjGf3+BEYOPomLTtiFw868pcLvoOM0TI4odlQDdVT7jqQFgbeBVWwPl3QLMBi43/aEnOfPwMe2/0/SYOA229dKOhg423b3aVz7SGAm26fnfYxmtv2FpHeBVYAFgKuB1Unt1i8Cl9o+T9IjwIG235K0OnCm7Q2ncZ8bgIttPyVpfuBB20tJGgAcZXuLnO9q4F7bt0naGNietAqR8ns+B5gA3AGsbXu8pN62Jxaem6/1IbCQ7UmSejZXc1955VX89LMvFMsS2qDXqodUugh1bdKoW/jh67HtEg2XWm5FX3XXo0XzrLlor2ElrqfbYTq6I2207eH58TBgQWDZHGx7knYbfjC/vjawXX58HXB2kes+D1wpaQbgroJ7NFgXuDOvFkQO6EjqDqwF3Fqw2HHXIvf5BbB0Qd5ZJfUokh9g43y8lJ93BxYDViD9URkPRXfmeAW4XtJdQIynCqEFqqXdtpiODrqTCh5PAbqRaqDb2H5Z0l7AgII8JVW7bT8haT1gc+A6SefavrZxtiZO7QR8art/acWnE7Bm43baZlanF6n2/I9G5xw6jTI1tjmwHqnZ4QRJy9ieXGJ5Q5iuVX/IrUxHWg9gTK6l7lqQ/jRpIzgapf+MpAWAsbYvB64AVmqU5Qlg29yG3APYEsD258BoSTvk60jSCkVu9RAw9ftlXsS4OQ8C++RaNZLmye3AjwA7Spo9pzfMGviC9JkgqRMwn+1HgWP48dtACKEZIlWIih0lXSf1DY3I/Swv5LTekoZIeiv/bP+NKTvQCcCzwBDgjYL0w4CDJT0PzNbMNQYAwyW9RGqS+Fvhi7ZfBG4GhgO3A08WvLwrsK+kl4GRQLHu80OBVXKn1mvAgc2UC9sPATcAz0gaAdwG9LA9EjgdeDzf+4J8yk3A0fm9LAYMyue9BPylTKMxQqh9ecGbYkcLbJBHIzW0/w4EHrG9GKkC1eoe4A7rSAvlER1pHSs60jpWe3akLb38ih40+PGieVZeaLZmO9IaOuQb+l9y2ihggO0xSvulPWZ7iWldo5i6GqcbQpieFW9aUOlbsBt4KA8rbXi9r+0xAPlnq2f1VPU0YEnLkUYyFJpke/V2vs+fgB0aJd9q+/T2vE8IoWOV0IRQyhbsa9v+MPfFDJH0RjP5W6Sqg67tEUCpIw3acp/TSe2tIYQalTrS2n4d2x/mn2Ml3QmsBnwsqV9B80KrV2qK5oUQQt1o6ypjkmZpGIsvaRbSmPtXSZOc9szZ9gTubm0Zq7qmG0IILdEOq4z1Be7M7b9dgBtsP5BHVd0iaV/gv/y8ObJkEXRDCPWhHVa1sf0f0uzRxukTgI3advUkgm4IoS6k9XSrf05aBN0QQt2o/pAbQTeEUEdKnepbSRF0Qwh1owZibgTdEEL9qIGYG0E3hFAfGlYZq3YRdEMI9aHlK4lVRATdEELdiKAbQghlU9pU30qLoBtCqAtpckSlS9G8CLohhPoRQTeEEMonpgGHEEIZVX/IjaAbQqgXNTJkLBYxDyHUhbZuwS5pPkmPSnpd0khJh+X0kyV9kLdkHy7pV20pZ9R0Qwh1o40V3cnAkbZfzLtHDJM0JL/2F9vntbF4QATdEEIdaUtHWt7lt2HH3y8kvQ7M005FmyqaF0II9UPNHKVtwY6kBYEVgWdz0iGSXpF0paRebSliBN0QQl2Q0uSIYgd5C/aC47KfX0fdgduBw21/DlwCLELamXwMcH5byhlBN4RQN9phN+AZSAH3ett3ANj+2PYU2z8Al5O2ZG+1CLohhLohFT+KnysBVwCv276gIL1fQbZtSVuyt1p0pIUQ6kYbx+muDewOjJA0PKcdB+wsqT9g4F3ggLbcJIJuCKEuCLV19MJTND3q7L5WX7QJ0bwQQghlFDXdEELdqIVpwBF0Qwj1QbHKWAghlM2P8x+qWwTdEELdiN2AQwihjGog5kbQDSHUjwi6IYRQRrWwG7BsV6nVqxsAABD2SURBVLoMoQ0kjQPeq3Q5WmAOYHylC1HHau3zXcB2n/a4kKQHSO+/mPG2N22P+7VWBN1QVpJesL1KpctRr+LzrX4xIy2EEMoogm4IIZRRBN1Qbj9bNDq0q/h8q1y06YYQQhlFTTeEEMoogm4IIZRRBN0QQiijCLohhFBGEXRDCKGMIuiGmpd3cUXSSpKWVC2s71ejCj7ruSpdlloVQTfUPNuWtBlwKzCrYxxkh5Ck/FlvClwjaYH4A9dyMU431KyCILAQacfWnWy/ImkJoCfwqu2vKlvK+iJpPeBKYA/b/5bUzfY3lS5XLYmgG2qOpFmAmWxPkLQY8DlwBPA90BlYFxgHPGj70sqVtPZJ6kL6MjFF0gzAQaTP+QZgB+C3wLO2D6tgMWtKNC+EWrQkcLGkg4C/AHMDrwPzAU8AWwKPAO2yZOD0SlJX0h+wBSRtDewGjABOIzXlzAb8CVhT0ooVK2iNiUXMQ82xPUzSF8D5wEG2X5I0ErgmNzesBuwNHFfRgta+74DFgBOABYEDbT8qaW1gou1xkuYnfbv4onLFrC1R0w01o6DnvDepZvsP4CBJy9n+LgfcVUhNDX+2/WB09LSOpE65Q/JuUlB9FRgjaWbbo3LA3QF4kPRZv13J8taSaNMNNSV/zd0J+KPt/0k6htS2uBnQFdgFuCm/phjJ0HIFHZQbAcsC1wP7kZpvbrP9L0mzAcsBXW0/Ep916aKmG2qGpDWBk4CLbP8PwPY5wG3AUFI77osFr0UQaIUccLcgtZe/YXs8cC5pG6BtJZ0IvAT8z/YjDedUrMA1Jmq6oWZI2hlYwfZASTMBk2BqkFgN+N72SxUtZB3In+1lwOW2n5Q0o+3v8kiGXYBlgKds31PRgtao6EgLVauJr6zfk37hsf1tzrOmpM62n6pEGevUFGB20iiRJ0mfO8C8tq9tyBRNCq0TzQuhKuVAakm/lLSfpANs3wbMJukqSQtL+gWpvTH+HbdBQQflwpIWJgXdq0lDxdbM/x/WAK6WtGjDeRFwWydquqGqSJrF9ld5MP6vgD8DxwL/yJMiNgBu5sdhTIfYfqJiBa5xeZTCD5K2AY4C3gPGAk8BXwNnSnoHWA/4Q4xSaLto0w1VQ9JSwOGkQPsBcAlwNqkH/Rhgd9ujC/LPYXt8fM1tOUlLAj1sPy9pceD/AZsChwFbAesAPYC5SH/cPrI9PD7rtouabqgKkmYELgAuAj4i/bJ/TwoCywL72B4taUdSh9mdwESIr7ktlVcIexzYIyd9CTwD/IY0m2/3/E1jEdvDgDcazo3Puu2iLSxUXF6wpivwKHAGaTjSx6RAcDBwnu03c7viKfk1bP9QmRLXrtxEMztp7YTZJV0NzECqzR5B+uP2tqRNSFOt561UWetVBN1QUZIWAJ4m9ZQ/B8wDfGN7iu3rSYHgYkl/JzU3HGP73xUrcA2TtDRp6vQkYFHgUuAx2+8BDwH/BnaTtBtpjO5ptt+vVHnrVbTphorK6+BuSKp57QL8E9gaWBrY1vbXktYirSTWKS/dGO2KLZTH3t4JDLZ9iaQjgTWBYcBdpCaEjUhtuTOQgvGQ+KzbXwTdUFG5fXEIqYa7je0n8lfgv+S07WO91vYhaVfgUKAv0J+0psLpwGfAVbbfyPk6255SsYLWuWheCBWThyt9RKpljQbmldQjLzx+KDABGByL1rSbccAKpGFhsj2BFHRnBvaXtFLOF23lHShquqHsGu348BHpl747aUD+raQlGr/KX4kXtf1q5Upb2wqbB/IiNQsD6+fjONuv53b144Dzbb9ZudJOHyLohoqQtBVp7O1LgEiLYS8FnEpq173C9peVK2HtK/jjtjmp/bY7cDwwI/A7YHngZNuvSepqe1IFizvdiOaFUHZ5MP7xpDGhX5M6zTrZHgqcCGwH9K5cCetDwzRq0jC7m4CNgb/bnghcAYwizTibhR/XVwgdLCZHhEqYhdR5tg5peulutj+RtIrtoZK2tP1ZZYtYN9YDDgQWAD4hLY0JqVnnfGAOx+adZRVBN1TCaGBV0mLkG+QFxzcFjpC0u+2PK1u8ujIJ+ANpxMJett/LS2T2tf1X4NOKlm46FM0LoRK+JC08/hCwV25zPJf01TcCbvt6BNgEuNH2W3lW3wmk7XdCBURHWqiIvM/ZcsDupKFhj9u+Lwbjt5+CjrRfAWcCw4HFgTNiAfLKiaAbKq5gecEIuO2sIPDOR2pqmCUvHBSfdYVE0A3truAXfQlgJuDdaXWMNRpHGoGghQo+687AD6V+fjHrrHIi6IYOkRfFPpa0VXpX4G95SFhhns55CcEeQHfbYypQ1JrVaBzuLqT1KR6zfXMTeRs+6xlsx/CwCoqOtNAuJHXKPztLWpA0+H4D0gpiiwKjCqfzFgSB2Uhru85d9kLXuBxwNwJOBs4hjUY6NK9NPFXBZ90TuCivdxEqJIJuaDNJcwLP550cppD+XY0ADgD2Bn5j+xNgDUkzNwq4dwCH5sWyQzMk9ZG0ZUHSvMBBwHykTTt3cdq5d56cv/CzvhMYlNe7CBUSQTe0me2xwFDgKUm9bf8HmBXYBzjI9ju5RnYp0K8gCDwEnOTYybck+dvEdsDWkn6dk2chrVlxJGkpzPfymOdDJHUvqOHeDZzg2E+u4qJNN7SJpC62J0uaA7ifNK9/HdJqVr8ljcl9k1QbO9r2vfm8tUlTf5+sTMlrS6MOx+NIzTG3kZpm7ib9Lm8paWPgb6RNJB+QNANpmcxbIuBWhwi6oc0kbQEcDVxD6tCZF1gZ6AdsBnQDnrP9WEO7boxSaJ38jeFI0gyzj0kB9mnSVvTfA32As23fV3BOH9vjKlDc0IQIuqHFckfM/Lafy88vAV62fWl+fhGwFrBhXlMhhoW1UuFoA6X9yu4CdiZtk34AMD9pttnTedhYL9vjc/4YFlaFok03tIikLsAA4HNJ3XPyBKBXfl2kLdR7As/m/FP/nUXALV1usrk2rysMP66VMiWPe/5/pBrvGZK2zwF2QsP5EXCrU9R0Q4tJ6kbqwDmH9Is/EXgKOMT2TZJWIwXmx20/W7GC1gFJC5OCrWyPknQmKbDeYvu/knYg7Sl3iu23KlnWUJqo6YaSNYzFJS06/j1pPda9SNu7/BI4XtKVpN0fXoqA23q5qYA8EmQX4IG808ZgUu32IkmHkxav+UcE3NoRNd1QkoLZT5sAe5CGg81NqmWtAJwNfEBqVpjV9siKFbbGFXzWawBf2R4h6WRgc2B74FvgV8BCwBO2H65caUNLRdANJcsB90LS2Nt/5bRZgH2BNUg7yg6pYBHrhtLW9BcBezYMq5N0IrAVsGtuauhkOzaRrDGxiHkoSUEH2u+AZyTtCOxPGrJ0LWk775jp1A6UNoo8G9jO9kuS+gM9bJ8qycCdklYBYmv6GhQ13VAySYcBA4EXgWeB70jtjeuRvgbHQirtIHdUnkKaaGKgP2mSyUO2/0/S4o5de2tW1HRDyWz/TdLrwKg83bQfqZ1xZtux7Uv7+QF4AViX1HE2kLTY+7L59bcrVK7QDqKmG0rSuP1QaZ+t40hrJ9xRuZLVvuYmMUhaHbgYON72/eUrWegIMWQslKSJDpvOwB9t31G4ZGMojaSFJJ0PaRJDwxCxJvItBxwOnGb7/visa1/UdMNUBUOV5iYNwJ/B9pfRS97+8qiPd4Bbbf8+p/2sxpsXrJnd9kexbkV9iJpumCoH3E2B20nLMF4paVGn/cum/lvJIxmQ1E3SohUqbs2SNKPtr4CNgd0knQvTrPFObgi4EWzrQwTdMJWkxYG/AseQdo99Drhe0nwNNd1cG5tcsEZr/BtqobzI+NakldkuB/aU9I/82tTAmz9rS+oFXCepawTe2he/MNO5Rm2Ek4An82D8t22fRxoatmHO26VgUexbgNNj6FLLSZqZ1E57q+1jSNuiD5B0AUwNvIWf9c3AlbYnVa7Uob3EkLHpXK5JrQ8sCbwHbC5pb9tX5SyfArPnvJPzjg93kXYhiAXIW+db4D+k9XCx/amkI4B7cu32sPxZ9yIF3NPis64fEXSnUwWdZg3DkUYBr5H2LDtdad+zt0jTTv9QcOqewLG2nyl3mWtVwWc9j+0Pchv568A1kla0/Q2p4/Jk4N/5nC6kReHPjIBbX2L0wnQsL8F4KnCM7Vck7QYsDMxF2oHgddKOD/cWBI5YGLsVlLZJPw54Ehhn+3xJZ5AWrnmYtPfZzraH5iafLkDP2PGh/kRNd/rWE/gFaVnGV4CbgB2BmUi13L/mQDu15zwCbstJWofUMbktaaudTfKwvKNIM856AnfZHgpTh4R9D0TArUPRkTYds/0Q8GtgH0k7255MakN8FXiwINDG16EWajT0a3ZgJ1KH2WqkNXAXI63YNtr2A44dkacbUdOdztkeLGkycFoeP3oNcEOly1WrJPWw/UUeebABsCAwEhhD2tNsX9svS9oO6A3MQe5QC9OHCLoB2/fljpuzJA0BPooZaC2Xh4L9U9KFwMuk9XBfI21JPxJYE/ggzzJbkLS9USz2Pp2JjrQwlWKr7jaTtC1pVbCJwMBcq92FFGTnJq0c9h/getu3VaygoWIi6IbQziT9kjR55Azb5+ZvETsBS5DG6F5qe2JM7Z0+RUdaCO0sb1m0N7BXQQflTaSx0HfanpjzRcCdDkVNN4QOIulXwGnAhbmDMoQIuiF0JElbAWeRxkNHB2WIoBtCR4sOylAogm4IIZRRdKSFEEIZRdANIYQyiqAbQghlFEE3hBDKKIJuqAqSpkgaLulVSbfmdQxae60Bku7Nj7eSNLBI3p6SfteKe5ws6ahS04tc58v2uG+oHRF0Q7X4xnZ/28sC3wEHFr6opMX/Xm0Ptn1WkSw9gRYH3RBaK4JuqEZPAotKWlDS65IuBl4E5pO0saRnJL2Ya8TdASRtKukNSU+R1ggmp+8l6e/5cV9Jd0p6OR9rkSYuLJJr2efmfEdLel7SK5JOKbjWnySNkvQwaR2Fkkm6S9IwSSMl7d/otfPz+3lEUp+ctoikB/I5T0pashWfY6hCEXRDVcmLw2wGjMhJSwDX2l4R+Ao4HviF7ZWAF4AjJM1E2sp8S9IqXnNN4/IXAo/bXgFYibTc4kDgnVzLPlrSxqQFxlcD+gMrS1pP0srAb4AVSUF91Ra+tX1srwysAhwqafacPgvwYn4/jwMn5fTLgN/nc44i7WMX6kCspxuqRTdJw/PjJ4ErSEshvtewjQ2wBrA08HTaRowZgWdIOxmPtv0WgKRBwE9qk9mGwB4wdduhz/KOu4U2zsdL+Xl3UhDuQVqs5ut8j8EtfH+H5mUfAebL15wA/EDarQNgEHBHrr2vBdya3ydA1xbeL1SpCLqhWnxju39hQg44XxUmAUNs79woX3+gvaZWirQD7z8a3ePw1t5D0gDS2gtr2v5a0mOkfeiaYtI30E8bfx6hPkTzQqglQ4G1JS0KaacGSYsDbwALSVok59t5Guc/AhyUz+0saVbgC1IttsGDpD3jGtqK51Hajv4JYFtJ3ST1IDVllGo24JMccJck1dgbdAK2z493AZ6y/TkwWtIOuQyStEIL7heqWATdUDPyojF7ATdKeoUUhJe0/S2pOeGfuSPtvWlc4jBgA0kjgGHAMrYnkJorXpV0bt6s8wbgmZzvNqCH7RdJzQDDgdtJTSDTcryk9xsO4AGgSy7zabncDb4ClpE0jNT8cWpO3xXYV9LLpLbnrUv9nEJ1iwVvQgihjKKmG0IIZRRBN4QQyiiCbgghlFEE3RBCKKMIuiGEUEYRdEMIoYwi6IYQQhn9f4WfceyDBxDaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels=['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('models/medical_trial_model.h5') is False:\n",
    "    model.save('models/medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.1616961 , -0.29105878,  0.43936232,  0.40426993, -0.37162292,\n",
       "          0.4311419 , -0.2115897 , -0.35249603, -0.5067647 ,  0.00349749,\n",
       "         -0.02508676, -0.13264284, -0.24789432, -0.41976738,  0.35286772,\n",
       "          0.70958567]], dtype=float32),\n",
       " array([ 0.        ,  0.        , -0.09558019, -0.11413409,  0.        ,\n",
       "        -0.12216934,  0.        ,  0.        ,  0.        ,  0.27723825,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.06348088,\n",
       "        -0.14295043], dtype=float32),\n",
       " array([[-0.04925844,  0.08872458, -0.2648513 ,  0.23567   , -0.26562285,\n",
       "         -0.34605065,  0.2627038 ,  0.10429481, -0.33247146,  0.25994614,\n",
       "         -0.11571755, -0.04491025, -0.3430905 ,  0.09421211, -0.06706735,\n",
       "          0.1180765 ,  0.23731223, -0.30746335, -0.049593  , -0.06899515,\n",
       "         -0.03419778,  0.19164541,  0.25171992,  0.05099222, -0.2685914 ,\n",
       "          0.12351978, -0.28295463, -0.24410105,  0.33759263, -0.03741038,\n",
       "          0.31587216, -0.21596129],\n",
       "        [-0.31359506, -0.15633859, -0.25802216,  0.08176681,  0.3137183 ,\n",
       "          0.0674139 , -0.00178501, -0.13048622, -0.08844543, -0.16498442,\n",
       "         -0.15421313,  0.28566912,  0.2075685 ,  0.28387126, -0.10802683,\n",
       "         -0.13350259, -0.01333585,  0.19503418, -0.0521552 , -0.1287544 ,\n",
       "         -0.24280293, -0.11392133,  0.32681373,  0.10469025, -0.04726517,\n",
       "          0.27001074, -0.09468669, -0.3091397 , -0.1173531 , -0.03634542,\n",
       "         -0.05996376, -0.10698724],\n",
       "        [-0.20711163, -0.11958275, -0.33341965,  0.19164455,  0.01060822,\n",
       "         -0.05389932, -0.07158065, -0.13451107,  0.12260666,  0.03604954,\n",
       "         -0.0532131 , -0.21456538, -0.18402806, -0.21927539, -0.30181593,\n",
       "         -0.2925467 , -0.1557836 ,  0.10953369,  0.49132502,  0.3737194 ,\n",
       "         -0.06834321,  0.14005011, -0.12874489,  0.16192241,  0.5948577 ,\n",
       "         -0.23677118,  0.482492  ,  0.42350253, -0.5223075 ,  0.59607077,\n",
       "         -0.0597035 ,  0.33183393],\n",
       "        [-0.18606384, -0.13403039, -0.27201   ,  0.5066255 , -0.07211253,\n",
       "         -0.14204195,  0.3020173 , -0.1939067 ,  0.23541027, -0.54781514,\n",
       "         -0.17479143, -0.15056682,  0.3270485 ,  0.0704723 , -0.25767994,\n",
       "          0.03697687, -0.2310678 ,  0.13585389,  0.2314243 ,  0.05742152,\n",
       "         -0.07795396, -0.00955752,  0.33686078,  0.11036015,  0.12368853,\n",
       "          0.23029707,  0.29739082,  0.41874862, -0.02205503,  0.6345632 ,\n",
       "          0.1412035 ,  0.11039127],\n",
       "        [-0.2000984 , -0.1929047 ,  0.17849436, -0.28980267, -0.13692896,\n",
       "          0.22798374,  0.28323355, -0.09460905, -0.16804244, -0.04128316,\n",
       "          0.24015376, -0.07192925,  0.01717475, -0.05861875,  0.25266287,\n",
       "         -0.32050318, -0.12615058, -0.2783475 , -0.06305614, -0.02933574,\n",
       "          0.18992415,  0.31537768,  0.2722843 ,  0.31124505, -0.1505659 ,\n",
       "         -0.16633557, -0.3366541 , -0.2408931 ,  0.16884103, -0.18635246,\n",
       "          0.06896329,  0.06869724],\n",
       "        [ 0.11125091,  0.11963733, -0.50533855,  0.08800463, -0.41724423,\n",
       "          0.33285365, -0.23873086, -0.16076148,  0.45054767, -0.22696252,\n",
       "         -0.0283752 , -0.49108344, -0.09393081,  0.02580288, -0.12081216,\n",
       "         -0.40107358,  0.0610342 , -0.1082707 ,  0.5248026 ,  0.37843767,\n",
       "         -0.61782044, -0.12445784, -0.3262328 ,  0.29323018,  0.49330962,\n",
       "          0.33695355,  0.05907072,  0.41571927, -0.33145484,  0.09402624,\n",
       "         -0.31257814,  0.5347492 ],\n",
       "        [ 0.26048884,  0.13476816,  0.12666544,  0.13717434,  0.01193842,\n",
       "         -0.18887688,  0.04100552, -0.18841326, -0.17351022,  0.21451071,\n",
       "         -0.22405273,  0.3190377 ,  0.33543572, -0.22650172,  0.0908193 ,\n",
       "         -0.2155464 ,  0.08177963,  0.22789815,  0.2618285 , -0.03361389,\n",
       "         -0.2980861 , -0.13023317,  0.12642586, -0.02878976,  0.31074473,\n",
       "          0.17545858,  0.21232882,  0.33854666,  0.21365753, -0.0513916 ,\n",
       "          0.07349661, -0.13141775],\n",
       "        [-0.26702946, -0.09784549,  0.013955  , -0.26257175,  0.10398638,\n",
       "         -0.01404789, -0.18717887,  0.23350629, -0.3266963 , -0.04701024,\n",
       "          0.08754364, -0.12238063, -0.26684862, -0.311134  , -0.2980294 ,\n",
       "         -0.2407015 , -0.32454446, -0.15900666,  0.06452194, -0.1021134 ,\n",
       "         -0.35166606,  0.35170767,  0.25715038,  0.20502535, -0.05104548,\n",
       "          0.17177817,  0.28390625, -0.3495522 , -0.05155748, -0.06296411,\n",
       "         -0.00129551,  0.15393451],\n",
       "        [ 0.21142688,  0.18753693, -0.2052833 , -0.10414006, -0.07816553,\n",
       "          0.18592408,  0.25328764,  0.00816771, -0.31612235,  0.2060459 ,\n",
       "          0.2933065 ,  0.06304461, -0.06796905, -0.10443836, -0.05130079,\n",
       "          0.08344099,  0.29869065,  0.04256308,  0.22361425,  0.20142356,\n",
       "         -0.0375424 , -0.21603017, -0.2290918 , -0.07045612, -0.261637  ,\n",
       "         -0.20205274, -0.0710091 , -0.31128725, -0.25430414, -0.27272743,\n",
       "         -0.09570733, -0.0030258 ],\n",
       "        [-0.11150421, -0.330998  ,  0.46793947,  0.000835  ,  0.21524793,\n",
       "         -0.24853456, -0.17676425, -0.00182268, -0.02655797,  0.471917  ,\n",
       "          0.20521411,  0.35260108, -0.06991327, -0.04799616, -0.07686836,\n",
       "          0.28029278, -0.15923525, -0.12273806,  0.2546402 ,  0.02346059,\n",
       "          0.03643469, -0.05325833, -0.2856939 , -0.15081862, -0.24677406,\n",
       "         -0.02191286, -0.07579111,  0.18742134,  0.36466795, -0.07164862,\n",
       "         -0.3224014 ,  0.22766249],\n",
       "        [ 0.19323882, -0.23546305, -0.2651878 , -0.3078362 ,  0.0656347 ,\n",
       "         -0.09035391,  0.21478608,  0.308239  , -0.04117814, -0.00638381,\n",
       "         -0.34056684,  0.04182249, -0.04849425, -0.12582275,  0.02242413,\n",
       "          0.02311385,  0.23135635,  0.33840516, -0.14876589,  0.25546822,\n",
       "          0.12704754, -0.16254142, -0.04629663, -0.12883432,  0.25467905,\n",
       "          0.13938949,  0.22238043, -0.04065755, -0.3518048 , -0.13235998,\n",
       "          0.17670098,  0.14776805],\n",
       "        [ 0.01380342,  0.23532471, -0.13531531,  0.19533387, -0.25848165,\n",
       "         -0.34131157, -0.1805657 ,  0.31728217,  0.12724927, -0.26492918,\n",
       "          0.25975665, -0.1065345 ,  0.05294082,  0.22819957,  0.25890943,\n",
       "         -0.052048  , -0.34429997, -0.32100075,  0.15338048, -0.34448826,\n",
       "          0.2578152 , -0.17954153,  0.01314509, -0.31444472, -0.08445561,\n",
       "          0.22038665, -0.01755685,  0.21461108, -0.00307241, -0.01590469,\n",
       "          0.12738883, -0.22461438],\n",
       "        [-0.01021352,  0.32041612,  0.11357835, -0.10763226, -0.11972342,\n",
       "         -0.0548752 , -0.13045461,  0.20343152,  0.24489006,  0.10443264,\n",
       "          0.10791674, -0.34097785,  0.31720695, -0.12278599, -0.2354811 ,\n",
       "         -0.13534491, -0.07558903, -0.07956702,  0.02453586,  0.04948133,\n",
       "         -0.28313687,  0.29292318,  0.06902635,  0.23892763,  0.33898637,\n",
       "         -0.21134563,  0.28086188, -0.13956237,  0.08797041,  0.33002904,\n",
       "         -0.03596088,  0.05666897],\n",
       "        [-0.26450863,  0.0240452 ,  0.30594411, -0.072831  , -0.15230952,\n",
       "          0.33040997, -0.30197617,  0.33511016, -0.11415382, -0.33431083,\n",
       "          0.08720401,  0.01000768, -0.16951124,  0.28564605,  0.21775582,\n",
       "         -0.2474153 , -0.30786088, -0.06686884, -0.06100824, -0.17941754,\n",
       "         -0.2934122 , -0.2328341 ,  0.08781701,  0.28528604, -0.11803494,\n",
       "         -0.25186172, -0.08000407, -0.27557498,  0.20357367,  0.3476101 ,\n",
       "          0.2723054 , -0.24670185],\n",
       "        [-0.20225176, -0.14043997, -0.28452122,  0.5346963 , -0.31217936,\n",
       "         -0.05503941, -0.17650491, -0.27235192,  0.03375553,  0.09663879,\n",
       "         -0.07859855, -0.25905558,  0.06580007, -0.14112517,  0.16012642,\n",
       "         -0.33905154, -0.09840852,  0.11077978,  0.34543294,  0.20074517,\n",
       "          0.12372931,  0.14458649, -0.35665083,  0.25912967,  0.2749828 ,\n",
       "          0.20408233,  0.15570813,  0.5510807 ,  0.0719955 ,  0.5107296 ,\n",
       "          0.2218358 ,  0.42624286],\n",
       "        [ 0.04885384,  0.2704269 , -0.17715544,  0.45748487, -0.2155079 ,\n",
       "         -0.3455899 ,  0.18421237,  0.12258258,  0.54968065, -0.47235924,\n",
       "         -0.06833278, -0.26720423, -0.3040831 , -0.13880558,  0.02591923,\n",
       "         -0.212836  ,  0.19140318, -0.0056923 ,  0.30628267,  0.4449003 ,\n",
       "         -0.35014173, -0.00305625,  0.17636323,  0.6131097 ,  0.37956628,\n",
       "         -0.250952  ,  0.5783639 ,  0.43111092, -0.19199426,  0.41892624,\n",
       "          0.10551718,  0.26331544]], dtype=float32),\n",
       " array([ 0.        , -0.01653499,  0.29865304, -0.08371867,  0.21185867,\n",
       "         0.        , -0.02048516,  0.        , -0.06598157,  0.24285007,\n",
       "        -0.05720104,  0.29485148,  0.        ,  0.        ,  0.        ,\n",
       "         0.25937757,  0.        ,  0.13293351, -0.12172434, -0.07806321,\n",
       "         0.2898229 ,  0.12903252, -0.00322292, -0.05742965, -0.04911166,\n",
       "        -0.00676229, -0.0739994 , -0.11740739,  0.19760984, -0.08789677,\n",
       "        -0.00138537, -0.11536778], dtype=float32),\n",
       " array([[ 0.1620458 , -0.29026693],\n",
       "        [ 0.35720232, -0.16094604],\n",
       "        [ 0.7173296 , -0.3947764 ],\n",
       "        [-0.69363886,  0.37917334],\n",
       "        [ 0.5356801 , -0.79933053],\n",
       "        [ 0.37149355,  0.22697523],\n",
       "        [ 0.31873444, -0.35265374],\n",
       "        [-0.03553498,  0.17409858],\n",
       "        [-0.01747223,  0.50083196],\n",
       "        [ 0.3903729 , -0.889836  ],\n",
       "        [-0.28153524, -0.23835582],\n",
       "        [ 0.35394707, -0.7158943 ],\n",
       "        [-0.0263578 ,  0.05735153],\n",
       "        [-0.0462724 , -0.32680017],\n",
       "        [-0.24932924,  0.3397101 ],\n",
       "        [ 0.18070826, -0.7718895 ],\n",
       "        [ 0.24169359, -0.35045147],\n",
       "        [ 0.31121352,  0.13936225],\n",
       "        [-0.61384493, -0.00642415],\n",
       "        [-0.60299367,  0.31553927],\n",
       "        [ 0.897298  , -0.13295121],\n",
       "        [ 0.31797072,  0.17951737],\n",
       "        [ 0.18610056, -0.3203765 ],\n",
       "        [-0.41015914,  0.30164242],\n",
       "        [-0.47637266,  0.70459336],\n",
       "        [-0.28133506, -0.22523703],\n",
       "        [-0.1859919 ,  0.43996096],\n",
       "        [-0.16393098,  0.47659597],\n",
       "        [ 0.64761317, -0.6070683 ],\n",
       "        [-0.48003367,  0.17107385],\n",
       "        [ 0.4137953 ,  0.3930621 ],\n",
       "        [-0.08621888,  0.5706491 ]], dtype=float32),\n",
       " array([ 0.16144003, -0.16143999], dtype=float32)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x1d13fab7cc8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model.to_json()\n",
    "\n",
    "Just model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model2.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_4\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_12_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_12\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_13\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
